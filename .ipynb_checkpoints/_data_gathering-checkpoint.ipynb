{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3fbb761",
   "metadata": {},
   "source": [
    "<h1><center> PPOL 5203 Data Science I: Final project <br><br> \n",
    "<font color='grey'> Reactions for shocking news <br><br>\n",
    "Sam Cohen, Gabriel Soto, Daniel Cardenas </center> <h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44f2c339",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabos\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\gabos\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# setup\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import yt_videos_comments as yt_vc\n",
    "#Import YouTubeDataAPI\n",
    "from youtube_api import YouTubeDataAPI\n",
    "from youtube_api.youtube_api_utils import *\n",
    "from dotenv import load_dotenv\n",
    "# hugging face\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef8a04d",
   "metadata": {},
   "source": [
    "### Pop News: Taylor Swift and Travis Kelce - Video data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "9872e265",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2023-09-12 00:00:00 10\n",
      "1 2023-09-13 00:00:00 34\n",
      "2 2023-09-14 00:00:00 25\n",
      "3 2023-09-15 00:00:00 40\n",
      "4 2023-09-16 00:00:00 17\n",
      "5 2023-09-17 00:00:00 20\n",
      "6 2023-09-18 00:00:00 23\n",
      "7 2023-09-19 00:00:00 28\n",
      "8 2023-09-20 00:00:00 43\n",
      "9 2023-09-21 00:00:00 59\n",
      "10 2023-09-22 00:00:00 34\n",
      "11 2023-09-23 00:00:00 21\n",
      "12 2023-09-24 00:00:00 22\n",
      "13 2023-09-25 00:00:00 46\n"
     ]
    }
   ],
   "source": [
    "api_key = \"AIzaSyCakkcjPuXV3Y2LCNS2dBuZBedV3NHjF18\"\n",
    "query = 'Swift, Kelce'\n",
    "start_date = '2023-09-12'\n",
    "n_days = 14\n",
    "df_videos = yt_vc.get_videos_after_ndays(api_key, query, start_date, n_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4a495860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(425, 16)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_videos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7fba9073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "day\n",
       "1     11\n",
       "2     33\n",
       "3     24\n",
       "4     43\n",
       "5     18\n",
       "6     20\n",
       "7     24\n",
       "8     30\n",
       "9     45\n",
       "10    61\n",
       "11    31\n",
       "12    19\n",
       "13    20\n",
       "14    46\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_videos.value_counts('day', sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffc6235",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_videos.to_csv('swift_pop_videodata.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8c89de",
   "metadata": {},
   "source": [
    "### Pop News: Taylor Swift and Travis Kelce - Comment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef38521d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments = yt_vc.get_comments_all_videos(api_key, df_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb93a4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_comments = yt_vc.get_comments_all_videos(api_key, df_videos, get_replies=False)\n",
    "pop_comments.to_csv('swift_pop_comments.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "4d75c1b6-6e1c-4633-8b3b-7b5da1540acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting comment data from csv. This DF will be used to make the analysis\n",
    "pop_comments_sentiment = pd.read_csv('swift_pop_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "8c7fa2e9-e26b-4af9-9c2f-54be29d8151d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49955, 15)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_comments_sentiment.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "6195fe1e-c9a4-4793-a57b-cd52a9ebae52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to truncate text from comments to limit of 512\n",
    "def truncate_text(text):\n",
    "    if isinstance(text, str):\n",
    "        return text[:512]\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "pop_comments_sentiment.loc[:, 'text'] = pop_comments_sentiment['text'].apply(truncate_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "cc54270f-5f3b-4ef0-a054-50904d5ff9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out NaN values before applying sentiment analysis\n",
    "pop_comments_sentiment_NA = pop_comments_sentiment.dropna(subset=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "bffed649-025f-42e3-b95f-f871030dec4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabos\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:105: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize the sentiment analyzer\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\", return_all_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "b56ce885-ada3-406e-9a2d-34e3c878fe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying sentiment analyzer onto dataset with tqdm to see progresse.\n",
    "tqdm.pandas(desc=\"Applying Sentiment Analysis\")\n",
    "pop_comments_sentiment_NA['sentiment'] = pop_comments_sentiment_NA['text'].progress_apply(lambda x: sentiment_analyzer(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a43e58-6a0e-4462-8082-3ad82f41ddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating 3 columns for sentiments and scores function\n",
    "def get_sentiment_score(sentiment_list, target_label):\n",
    "    for sentiment_dict in sentiment_list[0]:  \n",
    "        if sentiment_dict['label'] == target_label:\n",
    "            return sentiment_dict['score']\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "e79e2ecd-f122-487b-a427-cd2fa90db63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabos\\AppData\\Local\\Temp\\ipykernel_6984\\1936994779.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pop_comments_sentiment_NA['sentiment'] = pop_comments_sentiment_NA['text'].apply(lambda x: sentiment_analyzer(x))\n"
     ]
    }
   ],
   "source": [
    "# Create separate columns for 'positive', 'neutral', and 'negative'\n",
    "pop_comments_sentiment_NA['positive_score'] = pop_comments_sentiment_NA['sentiment'].apply(lambda x: get_sentiment_score(x, 'positive'))\n",
    "pop_comments_sentiment_NA['neutral_score'] = pop_comments_sentiment_NA['sentiment'].apply(lambda x: get_sentiment_score(x, 'neutral'))\n",
    "pop_comments_sentiment_NA['negative_score'] = pop_comments_sentiment_NA['sentiment'].apply(lambda x: get_sentiment_score(x, 'negative'))\n",
    "\n",
    "#csv file output after sentiment analysis\n",
    "pop_comments_sentiment_NA.to_csv('swift_pop_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "c00369c6-5d6f-475a-b73e-737d944f23d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>commenter_channel_url</th>\n",
       "      <th>commenter_channel_id</th>\n",
       "      <th>commenter_channel_display_name</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_like_count</th>\n",
       "      <th>comment_publish_date</th>\n",
       "      <th>text</th>\n",
       "      <th>commenter_rating</th>\n",
       "      <th>comment_parent_id</th>\n",
       "      <th>collection_date</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>day</th>\n",
       "      <th>day_published</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>positive_score</th>\n",
       "      <th>neutral_score</th>\n",
       "      <th>negative_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49953</th>\n",
       "      <td>TfkPKat54os</td>\n",
       "      <td>http://www.youtube.com/channel/UCSw2GxUpbENAV6...</td>\n",
       "      <td>UCSw2GxUpbENAV6SYqO2Zo_g</td>\n",
       "      <td>tasha J</td>\n",
       "      <td>UgypwTvtBy_KtnbutaR4AaABAg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.695746e+09</td>\n",
       "      <td>Damn I was just getting his jersey because he ...</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-11-28 17:44:11.069155</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>2023-09-25</td>\n",
       "      <td>2023-09-26 16:40:59</td>\n",
       "      <td>[[{'label': 'positive', 'score': 0.58100920915...</td>\n",
       "      <td>0.581009</td>\n",
       "      <td>0.080576</td>\n",
       "      <td>0.338415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49954</th>\n",
       "      <td>TfkPKat54os</td>\n",
       "      <td>http://www.youtube.com/channel/UC6n1yQzDCQq5bQ...</td>\n",
       "      <td>UC6n1yQzDCQq5bQVmN5bzG3Q</td>\n",
       "      <td>UTILIZE 3 EYES .â€¢.</td>\n",
       "      <td>UgyLOHBea505wYLOPwJ4AaABAg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.695729e+09</td>\n",
       "      <td>ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-11-28 17:44:11.069155</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>2023-09-25</td>\n",
       "      <td>2023-09-26 11:52:30</td>\n",
       "      <td>[[{'label': 'positive', 'score': 0.41610413789...</td>\n",
       "      <td>0.416104</td>\n",
       "      <td>0.258710</td>\n",
       "      <td>0.325186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          video_id                              commenter_channel_url  \\\n",
       "49953  TfkPKat54os  http://www.youtube.com/channel/UCSw2GxUpbENAV6...   \n",
       "49954  TfkPKat54os  http://www.youtube.com/channel/UC6n1yQzDCQq5bQ...   \n",
       "\n",
       "           commenter_channel_id commenter_channel_display_name  \\\n",
       "49953  UCSw2GxUpbENAV6SYqO2Zo_g                        tasha J   \n",
       "49954  UC6n1yQzDCQq5bQVmN5bzG3Q             UTILIZE 3 EYES .â€¢.   \n",
       "\n",
       "                       comment_id  comment_like_count  comment_publish_date  \\\n",
       "49953  UgypwTvtBy_KtnbutaR4AaABAg                   0          1.695746e+09   \n",
       "49954  UgyLOHBea505wYLOPwJ4AaABAg                   0          1.695729e+09   \n",
       "\n",
       "                                                    text commenter_rating  \\\n",
       "49953  Damn I was just getting his jersey because he ...             none   \n",
       "49954                                               ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚             none   \n",
       "\n",
       "       comment_parent_id             collection_date  reply_count  day  \\\n",
       "49953                NaN  2023-11-28 17:44:11.069155            0   14   \n",
       "49954                NaN  2023-11-28 17:44:11.069155            0   14   \n",
       "\n",
       "      day_published         publish_date  \\\n",
       "49953    2023-09-25  2023-09-26 16:40:59   \n",
       "49954    2023-09-25  2023-09-26 11:52:30   \n",
       "\n",
       "                                               sentiment  positive_score  \\\n",
       "49953  [[{'label': 'positive', 'score': 0.58100920915...        0.581009   \n",
       "49954  [[{'label': 'positive', 'score': 0.41610413789...        0.416104   \n",
       "\n",
       "       neutral_score  negative_score  \n",
       "49953       0.080576        0.338415  \n",
       "49954       0.258710        0.325186  "
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the modified DataFrame\n",
    "pop_comments_sentiment_NA.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b13687a",
   "metadata": {},
   "source": [
    "### Horrific News: Russia-Ukraine War - Video data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "229cdbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Ukraine, Russia, invasion'\n",
    "start_date = '2022-02-24'\n",
    "n_days = 14\n",
    "df_videos2 = yt_vc.get_videos_after_ndays(api_key, query, start_date, n_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f85eee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_videos2.value_counts('day_published')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a50ef1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_videos2.to_csv('ukraine_horrific_videodata.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3865c59",
   "metadata": {},
   "source": [
    "### Horrific News: Russia-Ukraine War - Comment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb9285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "horrific_comments = yt_vc.get_comments_all_videos(api_key, df_videos2, get_replies=False)\n",
    "horrific_comments.to_csv('ukraine_horrific_comments.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "834b70b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting comment data from csv. This DF will be used to make the analysis\n",
    "horrific_comments_sentiment = pd.read_csv('ukraine_horrific_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "c8a62a49-7bc1-4486-bbd2-1cc1b9a91053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(446233, 15)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horrific_comments_sentiment.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "b2bbdef7-178b-493a-9e8a-cefca096ec26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to truncate text from comments to limit of 512\n",
    "def truncate_text(text):\n",
    "    if isinstance(text, str):\n",
    "        return text[:512]\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "horrific_comments_sentiment.loc[:, 'text'] = horrific_comments_sentiment['text'].apply(truncate_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "1e2d46c7-f4e3-4447-9d36-85b99e86294f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out NaN values before applying sentiment analysis\n",
    "horrific_comments_sentiment_NA = horrific_comments_sentiment.dropna(subset=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "45147d32-a2c8-4a54-828a-03fda7324bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabos\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:105: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize the sentiment analyzer\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\", return_all_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c194cf88-d460-4e7c-ba89-09405014e475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_score(sentiment_list, target_label):\n",
    "    for sentiment_dict in sentiment_list[0]: \n",
    "        if sentiment_dict['label'] == target_label:\n",
    "            return sentiment_dict['score']\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b3b2b7-a228-467c-92ca-9941aee70b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting datasets\n",
    "total_rows = horrific_comments_sentiment_NA.shape[0]\n",
    "num_subsets = 10\n",
    "subset_size = total_rows // num_subsets\n",
    "subsets = [horrific_comments_sentiment_NA.iloc[i*subset_size : (i+1)*subset_size, :] for i in range(num_subsets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a26dd9-1919-4385-b024-13b7db7d7118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply sentiment analysis and create additional columns for each subset\n",
    "for i, subset in tqdm(enumerate(subsets), total=num_subsets, desc=\"Applying Sentiment Analysis\"):\n",
    "    # Apply sentiment analysis to the 'text' column\n",
    "    subset['sentiment'] = subset['text'].apply(lambda x: sentiment_analyzer(x))\n",
    "    \n",
    "    # Create separate columns for 'positive', 'neutral', and 'negative' scores\n",
    "    subset['positive_score'] = subset['sentiment'].apply(lambda x: get_sentiment_score(x, 'positive'))\n",
    "    subset['neutral_score'] = subset['sentiment'].apply(lambda x: get_sentiment_score(x, 'neutral'))\n",
    "    subset['negative_score'] = subset['sentiment'].apply(lambda x: get_sentiment_score(x, 'negative'))\n",
    "    \n",
    "    # Save each subset to a different CSV file\n",
    "    subset.to_csv(f'ukraine_scandal_sentiment_subset_{i + 1}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f50384-345d-46d1-844a-cf725f6cf39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the modified DataFrame\n",
    "subset.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc2c585-90b2-4ad6-ab34-a41800dad28c",
   "metadata": {},
   "source": [
    "### Horrific News: Uvalde-News - Comment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620ce194-2c8f-422a-9450-ad7a04432d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting comment data from csv. This DF will be used to make the analysis\n",
    "uvalde_horrific_sentiment0 = pd.read_csv('uvalde_horrific_comments.csv')\n",
    "uvalde_horrific_sentiment = uvalde_horrific_sentiment0.tail(171833)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2b32ee-77cf-43b9-b2b1-39250822b228",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Truncating data\n",
    "uvalde_horrific_sentiment.loc[:, 'text'] = uvalde_horrific_sentiment['text'].apply(truncate_text)\n",
    "\n",
    "# Filter out NaN values before applying sentiment analysis\n",
    "uvalde_horrific_sentiment_NA = uvalde_horrific_sentiment.dropna(subset=['text'])\n",
    "\n",
    "# Initialize the sentiment analyzer\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\", return_all_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65a8c26-6686-42d9-b734-dd17a1c81a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_score(sentiment_list, target_label):\n",
    "    for sentiment_dict in sentiment_list[0]:  # Access the first (and only) element in the list\n",
    "        if sentiment_dict['label'] == target_label:\n",
    "            return sentiment_dict['score']\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8b3cc4-e41a-4c10-b68a-7f9b1fe645a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subsetting dataset\n",
    "total_rows = uvalde_horrific_sentiment_NA.shape[0]\n",
    "num_subsets = 10\n",
    "subset_size = total_rows // num_subsets\n",
    "subsets = [uvalde_horrific_sentiment_NA.iloc[i*subset_size : (i+1)*subset_size, :] for i in range(num_subsets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52434817-368c-4572-a9e3-d6156c0ce43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply sentiment analysis and create additional columns for each subset\n",
    "for i, subset in tqdm(enumerate(subsets), total=num_subsets, desc=\"Applying Sentiment Analysis\"):\n",
    "    # Apply sentiment analysis to the 'text' column\n",
    "    subset['sentiment'] = subset['text'].apply(lambda x: sentiment_analyzer(x))\n",
    "    \n",
    "    # Create separate columns for 'positive', 'neutral', and 'negative' scores\n",
    "    subset['positive_score'] = subset['sentiment'].apply(lambda x: get_sentiment_score(x, 'positive'))\n",
    "    subset['neutral_score'] = subset['sentiment'].apply(lambda x: get_sentiment_score(x, 'neutral'))\n",
    "    subset['negative_score'] = subset['sentiment'].apply(lambda x: get_sentiment_score(x, 'negative'))\n",
    "    \n",
    "    # Save each subset to a different CSV file\n",
    "    subset.to_csv(f'uvalde_horrific_sentiment_subset_{i + 1}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d639309-8967-4881-94f5-f993c0d0c0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the modified DataFrame\n",
    "subset.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edefe519",
   "metadata": {},
   "source": [
    "### Scandalous News: Menendez Indictment - Video data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "1e77590a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2023-09-22 00:00:00 215\n",
      "1 2023-09-23 00:00:00 69\n",
      "2 2023-09-24 00:00:00 19\n",
      "3 2023-09-25 00:00:00 113\n",
      "4 2023-09-26 00:00:00 30\n",
      "5 2023-09-27 00:00:00 40\n",
      "6 2023-09-28 00:00:00 16\n",
      "7 2023-09-29 00:00:00 9\n",
      "8 2023-09-30 00:00:00 3\n",
      "9 2023-10-01 00:00:00 2\n",
      "10 2023-10-02 00:00:00 4\n",
      "11 2023-10-03 00:00:00 1\n",
      "12 2023-10-04 00:00:00 2\n",
      "13 2023-10-05 00:00:00 5\n"
     ]
    }
   ],
   "source": [
    "query = 'Menendez, indictment, bribe'\n",
    "start_date = '2023-09-22'\n",
    "n_days = 14\n",
    "df_videos3 = yt_vc.get_videos_after_ndays(api_key, query, start_date, n_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b9cc70e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "day\n",
       "1     201\n",
       "2      65\n",
       "3      14\n",
       "4     108\n",
       "5      31\n",
       "6      39\n",
       "7      16\n",
       "8       9\n",
       "9       3\n",
       "10      2\n",
       "11      4\n",
       "12      1\n",
       "13      2\n",
       "14      5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_videos3.value_counts('day', sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "efc05404",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_videos3.to_csv('menendez_scandal_videodata.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5c396d",
   "metadata": {},
   "source": [
    "### Scandalous News: Menendez Indictment - Video data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "798bc183",
   "metadata": {},
   "outputs": [],
   "source": [
    "scandal_comments = yt_vc.get_comments_all_videos(\"AIzaSyAkbD5Fxf8TtrlTy-b6wagZ4I2M5fdUofc\", df_videos3, get_replies=False)\n",
    "scandal_comments.to_csv('menendez_scandal_comments.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "0c9b5be7-b322-4ab8-981c-86345bdabde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting comment data from csv. This DF will be used to make the analysis\n",
    "menendez_scandal_sentiment = pd.read_csv('menendez_scandal_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "c692b0e2-fb84-461a-914d-65b55fd8f331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66202, 15)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "menendez_scandal_sentiment.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "9fc2c80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Truncating text\n",
    "menendez_scandal_sentiment.loc[:, 'text'] = menendez_scandal_sentiment['text'].apply(truncate_text)\n",
    "# Filter out NaN values before applying sentiment analysis\n",
    "menendez_scandal_sentiment_NA = menendez_scandal_sentiment.dropna(subset=['text'])\n",
    "\n",
    "# Initialize the sentiment analyzer\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\", return_all_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24137f4c-1fa7-4955-9d3c-e809b46d2de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using tqdm lib to see progress and applying sentiment model\n",
    "tqdm.pandas(desc=\"Applying Sentiment Analysis\")\n",
    "menendez_scandal_sentiment_NA['sentiment'] = menendez_scandal_sentiment_NA['text'].progress_apply(lambda x: sentiment_analyzer(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3fa04b-b7dc-48aa-a9ec-ca85cbe0cf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating 3 columns for sentiments and scores based on sentiment column from df\n",
    "def get_sentiment_score(sentiment_list, target_label):\n",
    "    for sentiment_dict in sentiment_list[0]:  # Access the first (and only) element in the list\n",
    "        if sentiment_dict['label'] == target_label:\n",
    "            return sentiment_dict['score']\n",
    "    return None\n",
    "\n",
    "# Create separate columns for 'positive', 'neutral', and 'negative'\n",
    "menendez_scandal_sentiment_NA['positive_score'] = menendez_scandal_sentiment_NA['sentiment'].apply(lambda x: get_sentiment_score(x, 'positive'))\n",
    "menendez_scandal_sentiment_NA['neutral_score'] = menendez_scandal_sentiment_NA['sentiment'].apply(lambda x: get_sentiment_score(x, 'neutral'))\n",
    "menendez_scandal_sentiment_NA['negative_score'] = menendez_scandal_sentiment_NA['sentiment'].apply(lambda x: get_sentiment_score(x, 'negative'))\n",
    "\n",
    "#csv file output after sentiment analysis\n",
    "menendez_scandal_sentiment_NA.to_csv('menendez_scandal_sentiment.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ecca32-2602-4c58-97e0-a5279dc9797e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the modified DataFrame\n",
    "menendez_scandal_sentiment_NA.head(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
